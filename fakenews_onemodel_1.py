#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Tue Jun  6 13:04:42 2023@author: hgiffard"""import pandas as pdimport numpy as npimport seaborn as snsimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom sklearn.metrics import classification_reportimport reimport stringdf_fake = pd.read_csv('data/fake.csv') df_true = pd.read_csv('data/true.csv') df_fake['type']=0df_true['type']=1print('Difference in news articles:',len(df_fake)-len(df_true))#faketruedata = fake.append(true, ignore_index=True)faketruedata = pd.concat([df_fake, df_true], axis=0, ignore_index=True)print(faketruedata.columns)#take out test set# Removing last 20 rows for manual testing #all true are at the end#random shuffling of data frame firstdf_merged = faketruedata.sample(frac = 1)df_merged.reset_index(inplace = True)df_merged.drop(["index"], axis = 1, inplace = True)#combine title and text under one col, textdf_merged['text'] = df_merged['title'] + df_merged['text']data = df_merged.drop(["title", "subject", "date"], axis = 1)#type as type booldata['type'] = data['type'].map({0: True, 1: False})      # Replace int by boolean#print(data.isnull().sum())#print(data.info())# leave out columns: title, subject, datemanual_testing = data.tail(10) #presume this is the validation data setfor i in range(44897,44887,-1):   data.drop([i], axis = 0, inplace = True)       #creating a function to process the textsdef wordopt(text):    text = text.lower()    text = re.sub('\[.*?\]', '', text)    text = re.sub("\\W"," ",text)     text = re.sub('https?://\S+|www\.\S+', '', text)    text = re.sub('<.*?>+', '', text)    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)    text = re.sub('\n', '', text)    text = re.sub('\w*\d\w*', '', text)        return textdata["text"] = data["text"].apply(wordopt)print("cleaned text")#defining dependent and indepdent variablesx = data["text"]y = data["type"]#splitting training and testingx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)#convert text to vectorsfrom sklearn.feature_extraction.text import TfidfVectorizervectorization = TfidfVectorizer()xv_train = vectorization.fit_transform(x_train)xv_test = vectorization.transform(x_test)print("\nvectorized\n")#then train modelfrom sklearn.ensemble import RandomForestClassifierRFC = RandomForestClassifier(random_state=0)RFC.fit(xv_train, y_train)pred_rfc = RFC.predict(xv_test)RFC.score(xv_test, y_test)print(classification_report(y_test, pred_rfc))print("Done with model")    #now look at the results for the manual testing set, which is 10 entries longprint("now the manual testing set")manual_x=manual_testing["text"].apply(wordopt) manual_xv_test = vectorization.transform(manual_x) #apply to column or dataframe? -- SPLIT Into X and Youtput_test=manual_testingoutput_test.reset_index(inplace = True)output_test.drop(["index"], axis = 1, inplace = True)output_test["Random Forest Pred"] = RFC.predict(manual_xv_test)output_test.rename(columns={"text": "words", "type": "original", "Random Forest Pred": "RFC Pred"})print(output_test)#news=str(input("you can try it. Enter a news article:") )#def output_lable(n):#    if n == 0:#        return "Fake News"#    elif n == 1:#        return "Not Fake News"#    #def manual_testing(news):#    testing_news = {"text":[news]}#    new_def_test = pd.DataFrame(testing_news)#    new_def_test["text"] = new_def_test["text"].apply(wordopt) #    new_x_test = new_def_test["text"]#    new_xv_test = vectorization.transform(new_x_test)#    pred_GBC = GBC.predict(new_xv_test)#    pred_RFC = RFC.predict(new_xv_test)#    return print("\n\nGBC Prediction: {} \nRFC Prediction: {}".format(output_lable(pred_GBC[0]), output_lable(pred_RFC[0])))                                                                              